params:
  seed: ${...seed}

  algo:
    name: saclag

  model:
    name: continuous_saclag

  network:
    name: sac_actor_critic_cost
    separate: True

    space:
      continuous:

    mlp:
      units: [400, 200, 100]
      activation: elu
      d2rl: False

      initializer:
        name: default
      regularizer:
        name: None

    log_std_bounds: [-5, 2]

  load_checkpoint: ${if:${...checkpoint},True,False} # flag which sets whether to load the checkpoint
  load_path: ${...checkpoint} # path to the checkpoint to load

  config:
    name: ${resolve_default:Humanoid,${....experiment}}
    full_experiment_name: ${.name}
    env_name: rlgpu
    multi_gpu: False
    mixed_precision: True
    normalize_input: True
    normalize_value: True
    value_bootstrap: True
    num_actors: ${....task.env.numEnvs}
    reward_shaper:
      scale_value: 0.01
    normalize_advantage: True
    gamma: 0.99
    max_epochs: 2000000
    num_steps_per_episode: 128
    save_best_after: 100
    save_frequency: 10000
    init_alpha: 1
    alpha_lr: 0.0001
    p_lr: 0.0001
    actor_lr: 0.0003
    critic_lr: 0.0003
    critic_tau: 0.005
    batch_size: 1024
    learnable_temperature: True
    num_seed_steps: 2 # total steps: num_actors * num_steps_per_episode * num_seed_steps
    replay_buffer_size: 1000000
    safety_bound: 150
    is_pid: True
    pid_kp: 0.
    pid_ki: 0.001
    pid_kd: 0.